{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel='stylesheet' href='../assets/css/main.css'/>\n",
    "\n",
    "# 4.2H: Spark SQL on Hadoop\n",
    "\n",
    "[Standalone lab](4.2-sql.md) |   [Hadoop lab](4.2H-spark-sql-hadoop.md)\n",
    "\n",
    "\n",
    "<img src=\"../assets/images/spark-and-hadoop-1.png\" style=\"border: 5px solid grey ; max-width:100%;\" />\n",
    "\n",
    "\n",
    "## Step 1 : Login to Hadoop node\n",
    "Instructor will provide details\n",
    "\n",
    "\n",
    "## Step 2 : Start PySpark shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "   $ pyspark \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And set the log level to WARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Load JSON into Dataframe\n",
    "Issue the following commands in Spark-shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "clickstream = spark.read.json(\"/data/clickstream/in-json/clickstream.json\")\n",
    "\n",
    "# inspect the schema\n",
    "clickstream.printSchema()\n",
    "\n",
    "# inspect data\n",
    "clickstream.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Methods available on Dataframe\n",
    "Use tab completion to explore methods available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clickstream.  HIT THE TAB KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 : Querying Dataframes\n",
    "\n",
    "**Find records that have cost > 100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "over100 = clickstream.filter(clickstream(\"cost\") > 100)\n",
    "over100.show()\n",
    "\n",
    "# count the records\n",
    "over100.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count records where action = 'click'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "clickstream.filter(\"action == 'clicked'\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count the number of visits from each domain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clickstream.groupBy(\"domain\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 : Querying Using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "scala"
     ],
     "id": ""
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# register the data frame as a temporary table\n",
    "clickstream.registerTempTable(\"clickstream\")\n",
    "\n",
    "# try sql queries\n",
    "spark.sql(\"select * from clickstream\").show\n",
    "\n",
    "# find all facebook traffic\n",
    "spark.sql(\"select * from clickstream where domain = 'facebook.com'\").show\n",
    "\n",
    "# count traffic per domain from highest to lowest\n",
    "spark.sql(\"select domain, count(*) as total from clickstream  group by domain order by total desc\").show\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7 : Load all JSON data\n",
    "Let's load all JSON files in `/data/clickstream/in-json` directory\n",
    "\n",
    "```python\n",
    "clicks = spark.read.json(\"/data/clickstream/in-json/\")\n",
    "clicks.count()\n",
    "\n",
    "clicks.groupBy(\"domain\").count().show()\n",
    "\n",
    "# repeat instructions from step 6\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
